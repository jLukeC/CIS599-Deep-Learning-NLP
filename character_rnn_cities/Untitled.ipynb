{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/af.txt\n",
      "train/cn.txt\n",
      "train/de.txt\n",
      "train/fi.txt\n",
      "train/fr.txt\n",
      "train/in.txt\n",
      "train/ir.txt\n",
      "train/pk.txt\n",
      "train/za.txt\n"
     ]
    }
   ],
   "source": [
    "category_data = {}\n",
    "category_labels = []\n",
    "for filename in glob.glob(\"train/*.txt\"):\n",
    "    print(filename)\n",
    "    category = filename.split('/')[-1].split('.')[0]\n",
    "    category_labels.append(category)\n",
    "    lines = open(filename, encoding = \"ISO-8859-1\").read().strip().split('\\n')\n",
    "    category_data[category] = lines\n",
    "    \n",
    "# Uncomment to see category_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Information\n",
      "------------------------\n",
      "Label: af, number of instances: 3000\n",
      "Label: cn, number of instances: 3000\n",
      "Label: de, number of instances: 3000\n",
      "Label: fi, number of instances: 3000\n",
      "Label: fr, number of instances: 3000\n",
      "Label: in, number of instances: 3000\n",
      "Label: ir, number of instances: 3000\n",
      "Label: pk, number of instances: 3000\n",
      "Label: za, number of instances: 3000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set Information\")\n",
    "print(\"------------------------\")\n",
    "print(\"\\n\".join([\"Label: {}, number of instances: {}\".format(k,len(v)) for k,v in category_data.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# my little one-hot-ification algorithm\n",
    "letter_vocabulary = string.ascii_lowercase + \" '\"\n",
    "def one_hot_ify(s,v):\n",
    "    if s not in v:\n",
    "        print(\"Error Not Found in Vocabulary:\",s)\n",
    "    return np.array([int(s==x) for x in v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ir', 'tirsi')\n",
      "('de', 'casillas de chicapierna')\n",
      "('de', 'ouro gertode')\n",
      "('fr', 'menglas')\n",
      "('pk', 'goth labarran')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def random_training_pair():\n",
    "    c = random.choice(list(category_data.keys()))\n",
    "    n = random.choice(category_data[c])\n",
    "    return (c,n)\n",
    "\n",
    "for _ in range (5):\n",
    "    print(random_training_pair())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def line_to_tensor(line):\n",
    "    return np.array([one_hot_ify(letter, letter_vocabulary) for letter in line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_text(name_tensor):\n",
    "    non_zero_indicies = [np.where(row)[0][0] for row in name_tensor]\n",
    "    return \"\".join([letter_vocabulary[i] for i in non_zero_indicies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair ('fr', 'le daouet')\n",
      "Category Tensor:\n",
      "[0 0 0 0 1 0 0 0 0]\n",
      "Name Tensor (One Hot Character Level):\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]]\n",
      "Name Tensor Back to Text:\n",
      "le daouet\n"
     ]
    }
   ],
   "source": [
    "(c,n) = random_training_pair()\n",
    "print(\"Pair {}\".format((c,n)))\n",
    "print(\"Category Tensor:\")\n",
    "print(one_hot_ify(c,category_labels))\n",
    "print(\"Name Tensor (One Hot Character Level):\")\n",
    "name_tensor = line_to_tensor(n)\n",
    "print(name_tensor)\n",
    "print(\"Name Tensor Back to Text:\")\n",
    "print(tensor_to_text(name_tensor))\n",
    "\n",
    "assert n = tensor_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair ('fi', 'petes')\n",
      "petes\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
